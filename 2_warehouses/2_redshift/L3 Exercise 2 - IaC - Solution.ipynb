{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 2: Creating Redshift Cluster using the AWS python SDK \n",
    "## An example of Infrastructure-as-code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import boto3\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "## STEP 0: (Prerequisite) Save the AWS Access key\n",
    "\n",
    "### 1. Create a new IAM user\n",
    "IAM service is a global service, meaning newly created IAM users are not restricted to a specific region by default.\n",
    "- Go to [AWS IAM service](https://console.aws.amazon.com/iam/home#/users) and click on the \"**Add user**\" button to create a new IAM user in your AWS account. \n",
    "- Choose a name of your choice. \n",
    "- Select \"*Programmatic access*\" as the access type. Click Next. \n",
    "- Choose the *Attach existing policies directly* tab, and select the \"**AdministratorAccess**\". Click Next. \n",
    "- Skip adding any tags. Click Next. \n",
    "- Review and create the user. It will show you a pair of access key ID and secret.\n",
    "- Take note of the pair of access key ID and secret. This pair is collectively known as **Access key**. \n",
    "\n",
    "<center>\n",
    "<img style=\"float: center;height:300px;\" src=\"images/AWS_IAM_1.png\"><br><br>\n",
    "Snapshot of a pair of an Access key\n",
    "</center>\n",
    "\n",
    "### <font color='red'>2. Save the access key and secret</font>\n",
    "Edit the file `dwh.cfg` in the same folder as this notebook and save the access key and secret against the following variables:\n",
    "```bash\n",
    "KEY= <YOUR_AWS_KEY>\n",
    "SECRET= <YOUR_AWS_SECRET>\n",
    "```\n",
    "    \n",
    "For example:\n",
    "```bash\n",
    "KEY=6JW3ATLQ34PH3AKI\n",
    "SECRET=wnoBHA+qUBFgwCRHJqgqrLU0i\n",
    "```\n",
    "\n",
    "### 3. Troubleshoot\n",
    "If your keys are not working, such as getting an `InvalidAccessKeyId` error, then you cannot retrieve them again. You have either of the following two options:\n",
    "\n",
    "1. **Option 1 - Create a new pair of access keys for the existing user**\n",
    "\n",
    " - Go to the [IAM dashboard](https://console.aws.amazon.com/iam/home) and view the details of the existing (Admin) user. \n",
    "\n",
    " - Select on the **Security credentials** tab, and click the **Create access key** button. It will generate a new pair of access key ID and secret.\n",
    "\n",
    " - Save the new access key ID and secret in your `dwh.cfg` file\n",
    "\n",
    "\n",
    "<center>\n",
    "<img style=\"float: center;height:450px;\" src=\"images/AWS_IAM_2.png\"><br><br>\n",
    "Snapshot of creating a new Access keys for the existing user\n",
    "</center>\n",
    "\n",
    "2. **Option 2 - Create a new IAM user with Admin access** - Refer to the instructions at the top. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load DWH Params from a file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting setuptools<67\n",
      "  Downloading setuptools-66.1.1-py3-none-any.whl (1.3 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: setuptools\n",
      "  Attempting uninstall: setuptools\n",
      "    Found existing installation: setuptools 67.4.0\n",
      "    Uninstalling setuptools-67.4.0:\n",
      "      Successfully uninstalled setuptools-67.4.0\n",
      "Successfully installed setuptools-66.1.1\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.1.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!PIP_REQUIRE_VIRTUALENV=false pip install \"setuptools<67\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: black in /home/cgebbe/.local/lib/python3.8/site-packages (21.12b0)\n",
      "Requirement already satisfied: nb_black in /home/cgebbe/.local/lib/python3.8/site-packages (1.0.7)\n",
      "Requirement already satisfied: python-dotenv in /home/cgebbe/.local/lib/python3.8/site-packages (1.0.0)\n",
      "Requirement already satisfied: typing-extensions>=3.10.0.0 in /home/cgebbe/.local/lib/python3.8/site-packages (from black) (4.3.0)\n",
      "Requirement already satisfied: platformdirs>=2 in /home/cgebbe/.local/lib/python3.8/site-packages (from black) (2.4.0)\n",
      "Requirement already satisfied: mypy-extensions>=0.4.3 in /home/cgebbe/.local/lib/python3.8/site-packages (from black) (0.4.3)\n",
      "Requirement already satisfied: tomli<2.0.0,>=0.2.6 in /home/cgebbe/.local/lib/python3.8/site-packages (from black) (1.2.2)\n",
      "Requirement already satisfied: click>=7.1.2 in /home/cgebbe/.local/lib/python3.8/site-packages (from black) (8.0.3)\n",
      "Requirement already satisfied: pathspec<1,>=0.9.0 in /home/cgebbe/.local/lib/python3.8/site-packages (from black) (0.9.0)\n",
      "Requirement already satisfied: ipython in /home/cgebbe/.local/lib/python3.8/site-packages (from nb_black) (7.30.1)\n",
      "Requirement already satisfied: backcall in /home/cgebbe/.local/lib/python3.8/site-packages (from ipython->nb_black) (0.2.0)\n",
      "Requirement already satisfied: decorator in /usr/lib/python3/dist-packages (from ipython->nb_black) (4.1.2)\n",
      "Requirement already satisfied: traitlets>=4.2 in /home/cgebbe/.local/lib/python3.8/site-packages (from ipython->nb_black) (5.1.1)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /home/cgebbe/.local/lib/python3.8/site-packages (from ipython->nb_black) (3.0.24)\n",
      "Requirement already satisfied: pygments in /home/cgebbe/.local/lib/python3.8/site-packages (from ipython->nb_black) (2.10.0)\n",
      "Requirement already satisfied: pexpect>4.3 in /home/cgebbe/.local/lib/python3.8/site-packages (from ipython->nb_black) (4.8.0)\n",
      "Requirement already satisfied: setuptools>=18.5 in /home/cgebbe/.local/lib/python3.8/site-packages (from ipython->nb_black) (66.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in /home/cgebbe/.local/lib/python3.8/site-packages (from ipython->nb_black) (0.18.1)\n",
      "Requirement already satisfied: pickleshare in /home/cgebbe/.local/lib/python3.8/site-packages (from ipython->nb_black) (0.7.5)\n",
      "Requirement already satisfied: matplotlib-inline in /home/cgebbe/.local/lib/python3.8/site-packages (from ipython->nb_black) (0.1.3)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /home/cgebbe/.local/lib/python3.8/site-packages (from jedi>=0.16->ipython->nb_black) (0.8.3)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /home/cgebbe/.local/lib/python3.8/site-packages (from pexpect>4.3->ipython->nb_black) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /home/cgebbe/.local/lib/python3.8/site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython->nb_black) (0.2.5)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.1.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!PIP_REQUIRE_VIRTUALENV=false pip install black nb_black python-dotenv\n",
    "%load_ext lab_black"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KSZOU\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv(override=True)\n",
    "print(os.environ[\"AWS_ACCESS_KEY_ID\"][-5:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Param</th>\n",
       "      <th>Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DWH_CLUSTER_TYPE</td>\n",
       "      <td>multi-node</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DWH_NUM_NODES</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DWH_NODE_TYPE</td>\n",
       "      <td>dc2.large</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DWH_CLUSTER_IDENTIFIER</td>\n",
       "      <td>dwhCluster</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DWH_DB</td>\n",
       "      <td>dwh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>DWH_DB_USER</td>\n",
       "      <td>dwhuser</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>DWH_DB_PASSWORD</td>\n",
       "      <td>Passw0rd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>DWH_PORT</td>\n",
       "      <td>5439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>DWH_IAM_ROLE_NAME</td>\n",
       "      <td>dwhRole</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Param       Value\n",
       "0        DWH_CLUSTER_TYPE  multi-node\n",
       "1           DWH_NUM_NODES           4\n",
       "2           DWH_NODE_TYPE   dc2.large\n",
       "3  DWH_CLUSTER_IDENTIFIER  dwhCluster\n",
       "4                  DWH_DB         dwh\n",
       "5             DWH_DB_USER     dwhuser\n",
       "6         DWH_DB_PASSWORD    Passw0rd\n",
       "7                DWH_PORT        5439\n",
       "8       DWH_IAM_ROLE_NAME     dwhRole"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import configparser\n",
    "import os\n",
    "\n",
    "config = configparser.ConfigParser()\n",
    "config.read_file(open(\"dwh.cfg\"))\n",
    "\n",
    "# AWS_DEFAULT_REGION=us-west-2\n",
    "\n",
    "KEY = os.environ[\"AWS_ACCESS_KEY_ID\"]\n",
    "SECRET = os.environ[\"AWS_SECRET_ACCESS_KEY\"]\n",
    "\n",
    "DWH_CLUSTER_TYPE = config.get(\"DWH\", \"DWH_CLUSTER_TYPE\")\n",
    "DWH_NUM_NODES = config.get(\"DWH\", \"DWH_NUM_NODES\")\n",
    "DWH_NODE_TYPE = config.get(\"DWH\", \"DWH_NODE_TYPE\")\n",
    "\n",
    "DWH_CLUSTER_IDENTIFIER = config.get(\"DWH\", \"DWH_CLUSTER_IDENTIFIER\")\n",
    "DWH_DB = config.get(\"DWH\", \"DWH_DB\")\n",
    "DWH_DB_USER = config.get(\"DWH\", \"DWH_DB_USER\")\n",
    "DWH_DB_PASSWORD = config.get(\"DWH\", \"DWH_DB_PASSWORD\")\n",
    "DWH_PORT = config.get(\"DWH\", \"DWH_PORT\")\n",
    "\n",
    "DWH_IAM_ROLE_NAME = config.get(\"DWH\", \"DWH_IAM_ROLE_NAME\")\n",
    "\n",
    "(DWH_DB_USER, DWH_DB_PASSWORD, DWH_DB)\n",
    "\n",
    "pd.DataFrame(\n",
    "    {\n",
    "        \"Param\": [\n",
    "            \"DWH_CLUSTER_TYPE\",\n",
    "            \"DWH_NUM_NODES\",\n",
    "            \"DWH_NODE_TYPE\",\n",
    "            \"DWH_CLUSTER_IDENTIFIER\",\n",
    "            \"DWH_DB\",\n",
    "            \"DWH_DB_USER\",\n",
    "            \"DWH_DB_PASSWORD\",\n",
    "            \"DWH_PORT\",\n",
    "            \"DWH_IAM_ROLE_NAME\",\n",
    "        ],\n",
    "        \"Value\": [\n",
    "            DWH_CLUSTER_TYPE,\n",
    "            DWH_NUM_NODES,\n",
    "            DWH_NODE_TYPE,\n",
    "            DWH_CLUSTER_IDENTIFIER,\n",
    "            DWH_DB,\n",
    "            DWH_DB_USER,\n",
    "            DWH_DB_PASSWORD,\n",
    "            DWH_PORT,\n",
    "            DWH_IAM_ROLE_NAME,\n",
    "        ],\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create clients for IAM, EC2, S3 and Redshift\n",
    "**Note**: We are creating these resources in the the **us-west-2** region. Choose the same region in the your AWS web console to the see these resources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import boto3\n",
    "\n",
    "ec2 = boto3.resource(\n",
    "    \"ec2\", region_name=\"us-west-2\", aws_access_key_id=KEY, aws_secret_access_key=SECRET\n",
    ")\n",
    "\n",
    "s3 = boto3.resource(\n",
    "    \"s3\", region_name=\"us-west-2\", aws_access_key_id=KEY, aws_secret_access_key=SECRET\n",
    ")\n",
    "\n",
    "iam = boto3.client(\n",
    "    \"iam\", aws_access_key_id=KEY, aws_secret_access_key=SECRET, region_name=\"us-west-2\"\n",
    ")\n",
    "\n",
    "redshift = boto3.client(\n",
    "    \"redshift\",\n",
    "    region_name=\"us-west-2\",\n",
    "    aws_access_key_id=KEY,\n",
    "    aws_secret_access_key=SECRET,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check out the sample data sources on S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ResponseMetadata': {'RequestId': '52B3SN6JD3YVF5MH',\n",
       "  'HostId': 'pBNnDMvTfAcmbxxZaHwQC8HIqYkSUdvmZnNU99RTPjMTOTrUD1f5JT5SZVEkc0QsLLrwx4MYOuY=',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amz-id-2': 'pBNnDMvTfAcmbxxZaHwQC8HIqYkSUdvmZnNU99RTPjMTOTrUD1f5JT5SZVEkc0QsLLrwx4MYOuY=',\n",
       "   'x-amz-request-id': '52B3SN6JD3YVF5MH',\n",
       "   'date': 'Mon, 08 May 2023 19:24:57 GMT',\n",
       "   'x-amz-bucket-region': 'us-west-2',\n",
       "   'content-type': 'application/xml',\n",
       "   'transfer-encoding': 'chunked',\n",
       "   'server': 'AmazonS3'},\n",
       "  'RetryAttempts': 0},\n",
       " 'IsTruncated': False,\n",
       " 'Marker': '',\n",
       " 'Contents': [{'Key': 'log-data/2018/11/2018-11-01-events.json',\n",
       "   'LastModified': datetime.datetime(2019, 4, 7, 3, 19, 44, tzinfo=tzutc()),\n",
       "   'ETag': '\"21bae37b41c56b66973312a07322b5e4\"',\n",
       "   'Size': 7151,\n",
       "   'StorageClass': 'STANDARD'},\n",
       "  {'Key': 'log-data/2018/11/2018-11-02-events.json',\n",
       "   'LastModified': datetime.datetime(2019, 4, 7, 3, 19, 44, tzinfo=tzutc()),\n",
       "   'ETag': '\"c726b249410a532cce10fa166ce8616c\"',\n",
       "   'Size': 83585,\n",
       "   'StorageClass': 'STANDARD'},\n",
       "  {'Key': 'log-data/2018/11/2018-11-03-events.json',\n",
       "   'LastModified': datetime.datetime(2019, 4, 7, 3, 19, 45, tzinfo=tzutc()),\n",
       "   'ETag': '\"696af259d3203446b846de7937b5810c\"',\n",
       "   'Size': 54084,\n",
       "   'StorageClass': 'STANDARD'},\n",
       "  {'Key': 'log-data/2018/11/2018-11-04-events.json',\n",
       "   'LastModified': datetime.datetime(2019, 4, 7, 3, 19, 45, tzinfo=tzutc()),\n",
       "   'ETag': '\"3d10cad17e2279b29da00756a885659b\"',\n",
       "   'Size': 85671,\n",
       "   'StorageClass': 'STANDARD'},\n",
       "  {'Key': 'log-data/2018/11/2018-11-05-events.json',\n",
       "   'LastModified': datetime.datetime(2019, 4, 7, 3, 19, 46, tzinfo=tzutc()),\n",
       "   'ETag': '\"5055eafc2dcd43d7a39486683857da01\"',\n",
       "   'Size': 189295,\n",
       "   'StorageClass': 'STANDARD'},\n",
       "  {'Key': 'log-data/2018/11/2018-11-06-events.json',\n",
       "   'LastModified': datetime.datetime(2019, 4, 7, 3, 19, 46, tzinfo=tzutc()),\n",
       "   'ETag': '\"c0594b7fad6851d5d47650caffa48ea0\"',\n",
       "   'Size': 85373,\n",
       "   'StorageClass': 'STANDARD'},\n",
       "  {'Key': 'log-data/2018/11/2018-11-07-events.json',\n",
       "   'LastModified': datetime.datetime(2019, 4, 7, 3, 19, 46, tzinfo=tzutc()),\n",
       "   'ETag': '\"e6b529f7305fe26eca5e5ef85aa2e014\"',\n",
       "   'Size': 97519,\n",
       "   'StorageClass': 'STANDARD'},\n",
       "  {'Key': 'log-data/2018/11/2018-11-08-events.json',\n",
       "   'LastModified': datetime.datetime(2019, 4, 7, 3, 19, 46, tzinfo=tzutc()),\n",
       "   'ETag': '\"8a037906ea14c4bd6ea23e2d5333aa13\"',\n",
       "   'Size': 102218,\n",
       "   'StorageClass': 'STANDARD'},\n",
       "  {'Key': 'log-data/2018/11/2018-11-09-events.json',\n",
       "   'LastModified': datetime.datetime(2019, 4, 7, 3, 19, 47, tzinfo=tzutc()),\n",
       "   'ETag': '\"ea4f34c437d8caa2634ff98bef315f2a\"',\n",
       "   'Size': 134804,\n",
       "   'StorageClass': 'STANDARD'},\n",
       "  {'Key': 'log-data/2018/11/2018-11-10-events.json',\n",
       "   'LastModified': datetime.datetime(2019, 4, 7, 3, 19, 47, tzinfo=tzutc()),\n",
       "   'ETag': '\"272eeb15e546f06009fb67600f426e0e\"',\n",
       "   'Size': 44076,\n",
       "   'StorageClass': 'STANDARD'},\n",
       "  {'Key': 'log-data/2018/11/2018-11-11-events.json',\n",
       "   'LastModified': datetime.datetime(2019, 4, 7, 3, 19, 47, tzinfo=tzutc()),\n",
       "   'ETag': '\"0a9258f19b565369bd89d87608530782\"',\n",
       "   'Size': 43711,\n",
       "   'StorageClass': 'STANDARD'},\n",
       "  {'Key': 'log-data/2018/11/2018-11-12-events.json',\n",
       "   'LastModified': datetime.datetime(2019, 4, 7, 3, 19, 47, tzinfo=tzutc()),\n",
       "   'ETag': '\"d72f8a08de7bd2d784d507956761e77e\"',\n",
       "   'Size': 99854,\n",
       "   'StorageClass': 'STANDARD'},\n",
       "  {'Key': 'log-data/2018/11/2018-11-13-events.json',\n",
       "   'LastModified': datetime.datetime(2019, 4, 7, 3, 19, 48, tzinfo=tzutc()),\n",
       "   'ETag': '\"03961d37b48699e3ff408fa5f01d45c4\"',\n",
       "   'Size': 186826,\n",
       "   'StorageClass': 'STANDARD'},\n",
       "  {'Key': 'log-data/2018/11/2018-11-14-events.json',\n",
       "   'LastModified': datetime.datetime(2019, 4, 7, 3, 19, 47, tzinfo=tzutc()),\n",
       "   'ETag': '\"c8013941ab0400803119f2c37b3e2708\"',\n",
       "   'Size': 217264,\n",
       "   'StorageClass': 'STANDARD'},\n",
       "  {'Key': 'log-data/2018/11/2018-11-15-events.json',\n",
       "   'LastModified': datetime.datetime(2019, 4, 7, 3, 19, 48, tzinfo=tzutc()),\n",
       "   'ETag': '\"ff98067209187a8963a2c0c18967f54f\"',\n",
       "   'Size': 243143,\n",
       "   'StorageClass': 'STANDARD'},\n",
       "  {'Key': 'log-data/2018/11/2018-11-16-events.json',\n",
       "   'LastModified': datetime.datetime(2019, 4, 7, 3, 19, 48, tzinfo=tzutc()),\n",
       "   'ETag': '\"d381c80c292b1e15c728bef591b40eb6\"',\n",
       "   'Size': 175491,\n",
       "   'StorageClass': 'STANDARD'},\n",
       "  {'Key': 'log-data/2018/11/2018-11-17-events.json',\n",
       "   'LastModified': datetime.datetime(2019, 4, 7, 3, 19, 48, tzinfo=tzutc()),\n",
       "   'ETag': '\"1d117c1dc8a530439eea91c79a9a11a2\"',\n",
       "   'Size': 66164,\n",
       "   'StorageClass': 'STANDARD'},\n",
       "  {'Key': 'log-data/2018/11/2018-11-18-events.json',\n",
       "   'LastModified': datetime.datetime(2019, 4, 7, 3, 19, 49, tzinfo=tzutc()),\n",
       "   'ETag': '\"f7845257f768de6d10ad3f43f8b2d6ba\"',\n",
       "   'Size': 75763,\n",
       "   'StorageClass': 'STANDARD'},\n",
       "  {'Key': 'log-data/2018/11/2018-11-19-events.json',\n",
       "   'LastModified': datetime.datetime(2019, 4, 7, 3, 19, 49, tzinfo=tzutc()),\n",
       "   'ETag': '\"e2fb42cee2c647beab13944f1452b8d8\"',\n",
       "   'Size': 150798,\n",
       "   'StorageClass': 'STANDARD'},\n",
       "  {'Key': 'log-data/2018/11/2018-11-20-events.json',\n",
       "   'LastModified': datetime.datetime(2019, 4, 7, 3, 19, 49, tzinfo=tzutc()),\n",
       "   'ETag': '\"28597cac7420f7260cc5ee8fdcb1fa59\"',\n",
       "   'Size': 174991,\n",
       "   'StorageClass': 'STANDARD'},\n",
       "  {'Key': 'log-data/2018/11/2018-11-21-events.json',\n",
       "   'LastModified': datetime.datetime(2019, 4, 7, 3, 19, 49, tzinfo=tzutc()),\n",
       "   'ETag': '\"5b811a1ee64982e60eb90234011227e8\"',\n",
       "   'Size': 242588,\n",
       "   'StorageClass': 'STANDARD'},\n",
       "  {'Key': 'log-data/2018/11/2018-11-22-events.json',\n",
       "   'LastModified': datetime.datetime(2019, 4, 7, 3, 19, 49, tzinfo=tzutc()),\n",
       "   'ETag': '\"0e02b7971550d80899ace62a56e96776\"',\n",
       "   'Size': 46181,\n",
       "   'StorageClass': 'STANDARD'},\n",
       "  {'Key': 'log-data/2018/11/2018-11-23-events.json',\n",
       "   'LastModified': datetime.datetime(2019, 4, 7, 3, 19, 49, tzinfo=tzutc()),\n",
       "   'ETag': '\"8c8f106d950a9c7768f8b2c5b63cb597\"',\n",
       "   'Size': 138647,\n",
       "   'StorageClass': 'STANDARD'},\n",
       "  {'Key': 'log-data/2018/11/2018-11-24-events.json',\n",
       "   'LastModified': datetime.datetime(2019, 4, 7, 3, 19, 50, tzinfo=tzutc()),\n",
       "   'ETag': '\"57c55089602d67e0421a214a1942adf6\"',\n",
       "   'Size': 170219,\n",
       "   'StorageClass': 'STANDARD'},\n",
       "  {'Key': 'log-data/2018/11/2018-11-25-events.json',\n",
       "   'LastModified': datetime.datetime(2019, 4, 7, 3, 19, 50, tzinfo=tzutc()),\n",
       "   'ETag': '\"354ce3dc842cc3a5c5c205574e31f082\"',\n",
       "   'Size': 26214,\n",
       "   'StorageClass': 'STANDARD'},\n",
       "  {'Key': 'log-data/2018/11/2018-11-26-events.json',\n",
       "   'LastModified': datetime.datetime(2019, 4, 7, 3, 19, 50, tzinfo=tzutc()),\n",
       "   'ETag': '\"62c3cf125b4c51111858c104b48ec56f\"',\n",
       "   'Size': 123576,\n",
       "   'StorageClass': 'STANDARD'},\n",
       "  {'Key': 'log-data/2018/11/2018-11-27-events.json',\n",
       "   'LastModified': datetime.datetime(2019, 4, 7, 3, 19, 51, tzinfo=tzutc()),\n",
       "   'ETag': '\"38fdb9ddad08ea8d38761281bd3e797f\"',\n",
       "   'Size': 141625,\n",
       "   'StorageClass': 'STANDARD'},\n",
       "  {'Key': 'log-data/2018/11/2018-11-28-events.json',\n",
       "   'LastModified': datetime.datetime(2019, 4, 7, 3, 19, 51, tzinfo=tzutc()),\n",
       "   'ETag': '\"958bb973e883807f00a35801b9191c7f\"',\n",
       "   'Size': 202910,\n",
       "   'StorageClass': 'STANDARD'},\n",
       "  {'Key': 'log-data/2018/11/2018-11-29-events.json',\n",
       "   'LastModified': datetime.datetime(2019, 4, 7, 3, 19, 51, tzinfo=tzutc()),\n",
       "   'ETag': '\"b83ce60beda7021c6ce1c05385bba969\"',\n",
       "   'Size': 168646,\n",
       "   'StorageClass': 'STANDARD'},\n",
       "  {'Key': 'log-data/2018/11/2018-11-30-events.json',\n",
       "   'LastModified': datetime.datetime(2019, 4, 7, 3, 19, 51, tzinfo=tzutc()),\n",
       "   'ETag': '\"350823c28fb33b855b08c3940f16d8d2\"',\n",
       "   'Size': 177211,\n",
       "   'StorageClass': 'STANDARD'}],\n",
       " 'Name': 'udacity-dend',\n",
       " 'Prefix': 'log-data/2018/11/',\n",
       " 'Delimiter': '/',\n",
       " 'MaxKeys': 1000,\n",
       " 'EncodingType': 'url'}"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s3 = boto3.resource(\"s3\")\n",
    "s3.meta.client.list_objects(\n",
    "    Bucket=\"udacity-dend\", Prefix=\"log-data/2018/11/\", Delimiter=\"/\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get\n",
    "bucket = s3.Bucket(\"udacity-dend\")\n",
    "cnt = 0\n",
    "for obj in bucket.objects.filter(Prefix=\"log-data/\"):\n",
    "    # print(obj.key)\n",
    "    cnt += 1\n",
    "cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3.ObjectSummary(bucket_name='udacity-dend', key='log-data/')\n",
      "s3.ObjectSummary(bucket_name='udacity-dend', key='log-data/2018/11/2018-11-01-events.json')\n",
      "s3.ObjectSummary(bucket_name='udacity-dend', key='log-data/2018/11/2018-11-02-events.json')\n",
      "s3.ObjectSummary(bucket_name='udacity-dend', key='log-data/2018/11/2018-11-03-events.json')\n",
      "s3.ObjectSummary(bucket_name='udacity-dend', key='log-data/2018/11/2018-11-04-events.json')\n",
      "s3.ObjectSummary(bucket_name='udacity-dend', key='log-data/2018/11/2018-11-05-events.json')\n",
      "s3.ObjectSummary(bucket_name='udacity-dend', key='log-data/2018/11/2018-11-06-events.json')\n",
      "s3.ObjectSummary(bucket_name='udacity-dend', key='log-data/2018/11/2018-11-07-events.json')\n",
      "s3.ObjectSummary(bucket_name='udacity-dend', key='log-data/2018/11/2018-11-08-events.json')\n",
      "s3.ObjectSummary(bucket_name='udacity-dend', key='log-data/2018/11/2018-11-09-events.json')\n",
      "s3.ObjectSummary(bucket_name='udacity-dend', key='log-data/2018/11/2018-11-10-events.json')\n",
      "s3.ObjectSummary(bucket_name='udacity-dend', key='log-data/2018/11/2018-11-11-events.json')\n",
      "s3.ObjectSummary(bucket_name='udacity-dend', key='log-data/2018/11/2018-11-12-events.json')\n",
      "s3.ObjectSummary(bucket_name='udacity-dend', key='log-data/2018/11/2018-11-13-events.json')\n",
      "s3.ObjectSummary(bucket_name='udacity-dend', key='log-data/2018/11/2018-11-14-events.json')\n",
      "s3.ObjectSummary(bucket_name='udacity-dend', key='log-data/2018/11/2018-11-15-events.json')\n",
      "s3.ObjectSummary(bucket_name='udacity-dend', key='log-data/2018/11/2018-11-16-events.json')\n",
      "s3.ObjectSummary(bucket_name='udacity-dend', key='log-data/2018/11/2018-11-17-events.json')\n",
      "s3.ObjectSummary(bucket_name='udacity-dend', key='log-data/2018/11/2018-11-18-events.json')\n",
      "s3.ObjectSummary(bucket_name='udacity-dend', key='log-data/2018/11/2018-11-19-events.json')\n",
      "s3.ObjectSummary(bucket_name='udacity-dend', key='log-data/2018/11/2018-11-20-events.json')\n",
      "s3.ObjectSummary(bucket_name='udacity-dend', key='log-data/2018/11/2018-11-21-events.json')\n",
      "s3.ObjectSummary(bucket_name='udacity-dend', key='log-data/2018/11/2018-11-22-events.json')\n",
      "s3.ObjectSummary(bucket_name='udacity-dend', key='log-data/2018/11/2018-11-23-events.json')\n",
      "s3.ObjectSummary(bucket_name='udacity-dend', key='log-data/2018/11/2018-11-24-events.json')\n",
      "s3.ObjectSummary(bucket_name='udacity-dend', key='log-data/2018/11/2018-11-25-events.json')\n",
      "s3.ObjectSummary(bucket_name='udacity-dend', key='log-data/2018/11/2018-11-26-events.json')\n",
      "s3.ObjectSummary(bucket_name='udacity-dend', key='log-data/2018/11/2018-11-27-events.json')\n",
      "s3.ObjectSummary(bucket_name='udacity-dend', key='log-data/2018/11/2018-11-28-events.json')\n",
      "s3.ObjectSummary(bucket_name='udacity-dend', key='log-data/2018/11/2018-11-29-events.json')\n",
      "s3.ObjectSummary(bucket_name='udacity-dend', key='log-data/2018/11/2018-11-30-events.json')\n"
     ]
    }
   ],
   "source": [
    "# s3://udacity-dend/log_data\n",
    "\n",
    "# sampleDbBucket =  s3.Bucket(\"awssampledbuswest2\")\n",
    "sampleDbBucket = s3.Bucket(\"udacity-dend\")\n",
    "for obj in sampleDbBucket.objects.filter(\n",
    "    Prefix=\"log-data\", MaxKeys=10\n",
    "):  # Prefix=\"ssbgz\"):\n",
    "    print(obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj.download_file(outdir / \"l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/mnt/sda1/projects/git/courses/udacity_data_engineer/2_warehouses/project/data')"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "outdir = Path().resolve().parent / \"project/data\"\n",
    "outdir.mkdir(exist_ok=True)\n",
    "outdir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download files to analyze locally\n",
    "filename = \"song_data/A/A/A/TRAAAAK128F9318786.json\"\n",
    "sampleDbBucket.download_file(filename, str(outdir / Path(filename).name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "# STEP 1: IAM ROLE\n",
    "- Create an IAM Role that makes Redshift able to access S3 bucket (ReadOnly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arn:aws:iam::422749391306:role/dwhRole\n"
     ]
    }
   ],
   "source": [
    "from botocore.exceptions import ClientError\n",
    "\n",
    "# 1.1 Create the role\n",
    "dwhRole = iam.create_role(\n",
    "    Path=\"/\",\n",
    "    RoleName=DWH_IAM_ROLE_NAME,\n",
    "    Description=\"Allows Redshift clusters to call AWS services on your behalf.\",\n",
    "    AssumeRolePolicyDocument=json.dumps(\n",
    "        {\n",
    "            \"Statement\": [\n",
    "                {\n",
    "                    \"Action\": \"sts:AssumeRole\",\n",
    "                    \"Effect\": \"Allow\",\n",
    "                    \"Principal\": {\"Service\": \"redshift.amazonaws.com\"},\n",
    "                }\n",
    "            ],\n",
    "            \"Version\": \"2012-10-17\",\n",
    "        }\n",
    "    ),\n",
    ")\n",
    "\n",
    "\n",
    "# 1.2 Attaching Policy\n",
    "iam.attach_role_policy(\n",
    "    RoleName=DWH_IAM_ROLE_NAME,\n",
    "    PolicyArn=\"arn:aws:iam::aws:policy/AmazonS3ReadOnlyAccess\",\n",
    ")[\"ResponseMetadata\"][\"HTTPStatusCode\"]\n",
    "\n",
    "# 1.3 Get the IAM role ARN\n",
    "roleArn = iam.get_role(RoleName=DWH_IAM_ROLE_NAME)[\"Role\"][\"Arn\"]\n",
    "\n",
    "print(roleArn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STEP 2:  Redshift Cluster\n",
    "\n",
    "- Create a [RedShift Cluster](https://console.aws.amazon.com/redshiftv2/home)\n",
    "- For complete arguments to `create_cluster`, see [docs](https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/redshift.html#Redshift.Client.create_cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Cluster': {'ClusterIdentifier': 'dwhcluster',\n",
       "  'NodeType': 'dc2.large',\n",
       "  'ClusterStatus': 'creating',\n",
       "  'ClusterAvailabilityStatus': 'Modifying',\n",
       "  'MasterUsername': 'dwhuser',\n",
       "  'DBName': 'dwh',\n",
       "  'AutomatedSnapshotRetentionPeriod': 1,\n",
       "  'ManualSnapshotRetentionPeriod': -1,\n",
       "  'ClusterSecurityGroups': [],\n",
       "  'VpcSecurityGroups': [{'VpcSecurityGroupId': 'sg-0603b384d90249a77',\n",
       "    'Status': 'active'}],\n",
       "  'ClusterParameterGroups': [{'ParameterGroupName': 'default.redshift-1.0',\n",
       "    'ParameterApplyStatus': 'in-sync'}],\n",
       "  'ClusterSubnetGroupName': 'default',\n",
       "  'VpcId': 'vpc-0a350b07cb4e30dd1',\n",
       "  'PreferredMaintenanceWindow': 'fri:09:00-fri:09:30',\n",
       "  'PendingModifiedValues': {'MasterUserPassword': '****'},\n",
       "  'ClusterVersion': '1.0',\n",
       "  'AllowVersionUpgrade': True,\n",
       "  'NumberOfNodes': 4,\n",
       "  'PubliclyAccessible': True,\n",
       "  'Encrypted': False,\n",
       "  'Tags': [],\n",
       "  'EnhancedVpcRouting': False,\n",
       "  'IamRoles': [{'IamRoleArn': 'arn:aws:iam::422749391306:role/dwhRole',\n",
       "    'ApplyStatus': 'adding'}],\n",
       "  'MaintenanceTrackName': 'current',\n",
       "  'DeferredMaintenanceWindows': [],\n",
       "  'NextMaintenanceWindowStartTime': datetime.datetime(2023, 5, 12, 9, 0, tzinfo=tzutc()),\n",
       "  'AquaConfiguration': {'AquaStatus': 'disabled',\n",
       "   'AquaConfigurationStatus': 'auto'}},\n",
       " 'ResponseMetadata': {'RequestId': '4e9bb7bf-87ed-4bd7-86d8-193fd4e23e42',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amzn-requestid': '4e9bb7bf-87ed-4bd7-86d8-193fd4e23e42',\n",
       "   'content-type': 'text/xml',\n",
       "   'content-length': '2445',\n",
       "   'date': 'Sun, 07 May 2023 18:58:18 GMT'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "redshift.create_cluster(\n",
    "    # HW\n",
    "    ClusterType=DWH_CLUSTER_TYPE,\n",
    "    NodeType=DWH_NODE_TYPE,\n",
    "    NumberOfNodes=int(DWH_NUM_NODES),\n",
    "    # Identifiers & Credentials\n",
    "    DBName=DWH_DB,\n",
    "    ClusterIdentifier=DWH_CLUSTER_IDENTIFIER,\n",
    "    MasterUsername=DWH_DB_USER,\n",
    "    MasterUserPassword=DWH_DB_PASSWORD,\n",
    "    # Roles (for s3 access)\n",
    "    IamRoles=[roleArn],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "## 2.1 *Describe* the cluster to see its status\n",
    "- run this block several times until the cluster status becomes `Available`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_594/716511557.py:2: FutureWarning: Passing a negative integer is deprecated in version 1.0 and will not be supported in future version. Instead, use None to not limit the column width.\n",
      "  pd.set_option(\"display.max_colwidth\", -1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Key</th>\n",
       "      <th>Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ClusterIdentifier</td>\n",
       "      <td>dwhcluster</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NodeType</td>\n",
       "      <td>dc2.large</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ClusterStatus</td>\n",
       "      <td>available</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MasterUsername</td>\n",
       "      <td>dwhuser</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DBName</td>\n",
       "      <td>dwh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Endpoint</td>\n",
       "      <td>{'Address': 'dwhcluster.cfzknkwsvs9a.us-west-2.redshift.amazonaws.com', 'Port': 5439}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>VpcId</td>\n",
       "      <td>vpc-0a350b07cb4e30dd1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NumberOfNodes</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Key  \\\n",
       "0  ClusterIdentifier   \n",
       "1  NodeType            \n",
       "2  ClusterStatus       \n",
       "3  MasterUsername      \n",
       "4  DBName              \n",
       "5  Endpoint            \n",
       "6  VpcId               \n",
       "7  NumberOfNodes       \n",
       "\n",
       "                                                                                   Value  \n",
       "0  dwhcluster                                                                             \n",
       "1  dc2.large                                                                              \n",
       "2  available                                                                              \n",
       "3  dwhuser                                                                                \n",
       "4  dwh                                                                                    \n",
       "5  {'Address': 'dwhcluster.cfzknkwsvs9a.us-west-2.redshift.amazonaws.com', 'Port': 5439}  \n",
       "6  vpc-0a350b07cb4e30dd1                                                                  \n",
       "7  4                                                                                      "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def prettyRedshiftProps(props):\n",
    "    pd.set_option(\"display.max_colwidth\", -1)\n",
    "    keysToShow = [\n",
    "        \"ClusterIdentifier\",\n",
    "        \"NodeType\",\n",
    "        \"ClusterStatus\",\n",
    "        \"MasterUsername\",\n",
    "        \"DBName\",\n",
    "        \"Endpoint\",\n",
    "        \"NumberOfNodes\",\n",
    "        \"VpcId\",\n",
    "    ]\n",
    "    x = [(k, v) for k, v in props.items() if k in keysToShow]\n",
    "    return pd.DataFrame(data=x, columns=[\"Key\", \"Value\"])\n",
    "\n",
    "\n",
    "myClusterProps = redshift.describe_clusters(ClusterIdentifier=DWH_CLUSTER_IDENTIFIER)[\n",
    "    \"Clusters\"\n",
    "][0]\n",
    "prettyRedshiftProps(myClusterProps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "<h2> 2.2 Take note of the cluster <font color='red'> endpoint and role ARN </font> </h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'>DO NOT RUN THIS unless the cluster status becomes \"Available\". Make ure you are checking your Amazon Redshift cluster in the **us-west-2** region. </font>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DWH_ENDPOINT ::  dwhcluster.cfzknkwsvs9a.us-west-2.redshift.amazonaws.com\n",
      "DWH_ROLE_ARN ::  arn:aws:iam::422749391306:role/dwhRole\n"
     ]
    }
   ],
   "source": [
    "DWH_ENDPOINT = myClusterProps[\"Endpoint\"][\"Address\"]\n",
    "DWH_ROLE_ARN = myClusterProps[\"IamRoles\"][0][\"IamRoleArn\"]\n",
    "print(\"DWH_ENDPOINT :: \", DWH_ENDPOINT)\n",
    "print(\"DWH_ROLE_ARN :: \", DWH_ROLE_ARN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STEP 3: Open an incoming  TCP port to access the cluster ednpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ec2.SecurityGroup(id='sg-0603b384d90249a77')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Return': True,\n",
       " 'SecurityGroupRules': [{'SecurityGroupRuleId': 'sgr-0b39f37b7805bf225',\n",
       "   'GroupId': 'sg-0603b384d90249a77',\n",
       "   'GroupOwnerId': '422749391306',\n",
       "   'IsEgress': False,\n",
       "   'IpProtocol': 'tcp',\n",
       "   'FromPort': 5439,\n",
       "   'ToPort': 5439,\n",
       "   'CidrIpv4': '0.0.0.0/0'}],\n",
       " 'ResponseMetadata': {'RequestId': 'fde5bd85-c0df-48bc-a093-f89e912e97c7',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amzn-requestid': 'fde5bd85-c0df-48bc-a093-f89e912e97c7',\n",
       "   'cache-control': 'no-cache, no-store',\n",
       "   'strict-transport-security': 'max-age=31536000; includeSubDomains',\n",
       "   'content-type': 'text/xml;charset=UTF-8',\n",
       "   'content-length': '723',\n",
       "   'date': 'Sun, 07 May 2023 19:01:12 GMT',\n",
       "   'server': 'AmazonEC2'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vpc = ec2.Vpc(id=myClusterProps[\"VpcId\"])\n",
    "\n",
    "defaultSg = list(vpc.security_groups.all())[0]\n",
    "print(defaultSg)\n",
    "defaultSg.authorize_ingress(\n",
    "    GroupName=defaultSg.group_name,\n",
    "    CidrIp=\"0.0.0.0/0\",\n",
    "    IpProtocol=\"TCP\",\n",
    "    FromPort=int(DWH_PORT),\n",
    "    ToPort=int(DWH_PORT),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STEP 4: Make sure you can connect to the cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: ipython-sql in /home/cgebbe/.local/lib/python3.8/site-packages (0.5.0)\n",
      "Requirement already satisfied: psycopg2 in /home/cgebbe/.local/lib/python3.8/site-packages (2.9.6)\n",
      "Requirement already satisfied: six in /home/cgebbe/.local/lib/python3.8/site-packages (from ipython-sql) (1.16.0)\n",
      "Requirement already satisfied: prettytable in /home/cgebbe/.local/lib/python3.8/site-packages (from ipython-sql) (3.7.0)\n",
      "Requirement already satisfied: sqlalchemy>=2.0 in /home/cgebbe/.local/lib/python3.8/site-packages (from ipython-sql) (2.0.12)\n",
      "Requirement already satisfied: sqlparse in /home/cgebbe/.local/lib/python3.8/site-packages (from ipython-sql) (0.4.4)\n",
      "Requirement already satisfied: ipython in /home/cgebbe/.local/lib/python3.8/site-packages (from ipython-sql) (7.30.1)\n",
      "Requirement already satisfied: ipython-genutils in /usr/lib/python3/dist-packages (from ipython-sql) (0.2.0)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /usr/lib/python3/dist-packages (from sqlalchemy>=2.0->ipython-sql) (0.4.12)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in /home/cgebbe/.local/lib/python3.8/site-packages (from sqlalchemy>=2.0->ipython-sql) (4.3.0)\n",
      "Requirement already satisfied: pygments in /home/cgebbe/.local/lib/python3.8/site-packages (from ipython->ipython-sql) (2.10.0)\n",
      "Requirement already satisfied: pickleshare in /home/cgebbe/.local/lib/python3.8/site-packages (from ipython->ipython-sql) (0.7.5)\n",
      "Requirement already satisfied: traitlets>=4.2 in /home/cgebbe/.local/lib/python3.8/site-packages (from ipython->ipython-sql) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in /home/cgebbe/.local/lib/python3.8/site-packages (from ipython->ipython-sql) (0.18.1)\n",
      "Requirement already satisfied: setuptools>=18.5 in /home/cgebbe/.local/lib/python3.8/site-packages (from ipython->ipython-sql) (66.1.1)\n",
      "Requirement already satisfied: matplotlib-inline in /home/cgebbe/.local/lib/python3.8/site-packages (from ipython->ipython-sql) (0.1.3)\n",
      "Requirement already satisfied: pexpect>4.3 in /home/cgebbe/.local/lib/python3.8/site-packages (from ipython->ipython-sql) (4.8.0)\n",
      "Requirement already satisfied: decorator in /usr/lib/python3/dist-packages (from ipython->ipython-sql) (4.1.2)\n",
      "Requirement already satisfied: backcall in /home/cgebbe/.local/lib/python3.8/site-packages (from ipython->ipython-sql) (0.2.0)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /home/cgebbe/.local/lib/python3.8/site-packages (from ipython->ipython-sql) (3.0.24)\n",
      "Requirement already satisfied: wcwidth in /home/cgebbe/.local/lib/python3.8/site-packages (from prettytable->ipython-sql) (0.2.5)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /home/cgebbe/.local/lib/python3.8/site-packages (from jedi>=0.16->ipython->ipython-sql) (0.8.3)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /home/cgebbe/.local/lib/python3.8/site-packages (from pexpect>4.3->ipython->ipython-sql) (0.7.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.1.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting psycopg2-binary\n",
      "  Downloading psycopg2_binary-2.9.6-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: psycopg2-binary\n",
      "Successfully installed psycopg2-binary-2.9.6\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.1.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!PIP_REQUIRE_VIRTUALENV=false pip install ipython-sql psycopg2\n",
    "!PIP_REQUIRE_VIRTUALENV=false pip install --upgrade psycopg2-binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The sql extension is already loaded. To reload it, use:\n",
      "  %reload_ext sql\n"
     ]
    }
   ],
   "source": [
    "%load_ext sql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'dwh'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DWH_DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'DWH_ENDPOINT' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_9913/2042208328.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# Connect to Redshift using psycopg2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m conn = psycopg2.connect(\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mhost\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mDWH_ENDPOINT\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0mport\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5439\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mdbname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mDWH_DB\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'DWH_ENDPOINT' is not defined"
     ]
    }
   ],
   "source": [
    "import psycopg2\n",
    "import ssl\n",
    "from pprint import pprint\n",
    "\n",
    "# Set up the SSL context\n",
    "# ssl_context = ssl.SSLContext(ssl.PROTOCOL_TLSv1_2)\n",
    "from psycopg2.extras import RealDictRow\n",
    "from psycopg2.extras import RealDictCursor\n",
    "\n",
    "# Connect to Redshift using psycopg2\n",
    "conn = psycopg2.connect(\n",
    "    host=DWH_ENDPOINT,\n",
    "    port=5439,\n",
    "    dbname=DWH_DB,\n",
    "    user=DWH_DB_USER,\n",
    "    password=DWH_DB_PASSWORD,\n",
    "    # sslmode='require',\n",
    "    # connection_factory=ssl_context.wraap_socket,\n",
    ")\n",
    "\n",
    "\n",
    "query = \"\"\"\n",
    "SELECT *\n",
    "FROM event_stage_table\n",
    "WHERE ts==1541105830796\n",
    "LIMIT 3\n",
    "\"\"\"\n",
    "# query = \"SELECT COUNT(*) FROM event_stage_table WHERE userId != 0;\"\n",
    "# query = \"DROP TABLE IF EXISTS event_stage_table;\"\n",
    "\n",
    "\n",
    "\n",
    "# Use the connection to execute SQL queries\n",
    "# cur = conn.cursor()\n",
    "# cur = conn.cursor(cursor_factory=RealDictRow)\n",
    "cur = conn.cursor(cursor_factory=RealDictCursor)\n",
    "\n",
    "# cur.execute(f\"SELECT datname FROM pg_database;\")\n",
    "# cur.execute(f'SELECT * FROM dev')\n",
    "# cur.execute(\"SELECT tablename FROM pg_tables WHERE schemaname = 'public'\")\n",
    "cur.execute(query.strip())\n",
    "for row in cur.fetchall():\n",
    "    pprint(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "postgresql://dwhuser:Passw0rd@dwhcluster.cfzknkwsvs9a.us-west-2.redshift.amazonaws.com:5439/dwh\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/cgebbe/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py\", line 1963, in _exec_single_context\n",
      "    self.dialect.do_execute(\n",
      "  File \"/home/cgebbe/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py\", line 920, in do_execute\n",
      "    cursor.execute(statement, parameters)\n",
      "psycopg2.errors.UndefinedObject: unrecognized configuration parameter \"standard_conforming_strings\"\n",
      "\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/cgebbe/.local/lib/python3.8/site-packages/sql/magic.py\", line 196, in execute\n",
      "    conn = sql.connection.Connection.set(\n",
      "  File \"/home/cgebbe/.local/lib/python3.8/site-packages/sql/connection.py\", line 70, in set\n",
      "    cls.current = existing or Connection(descriptor, connect_args, creator)\n",
      "  File \"/home/cgebbe/.local/lib/python3.8/site-packages/sql/connection.py\", line 55, in __init__\n",
      "    self.internal_connection = engine.connect()\n",
      "  File \"/home/cgebbe/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py\", line 3264, in connect\n",
      "    return self._connection_cls(self)\n",
      "  File \"/home/cgebbe/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py\", line 145, in __init__\n",
      "    self._dbapi_connection = engine.raw_connection()\n",
      "  File \"/home/cgebbe/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py\", line 3288, in raw_connection\n",
      "    return self.pool.connect()\n",
      "  File \"/home/cgebbe/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py\", line 452, in connect\n",
      "    return _ConnectionFairy._checkout(self)\n",
      "  File \"/home/cgebbe/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py\", line 1268, in _checkout\n",
      "    fairy = _ConnectionRecord.checkout(pool)\n",
      "  File \"/home/cgebbe/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py\", line 716, in checkout\n",
      "    rec = pool._do_get()\n",
      "  File \"/home/cgebbe/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py\", line 169, in _do_get\n",
      "    self._dec_overflow()\n",
      "  File \"/home/cgebbe/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py\", line 147, in __exit__\n",
      "    raise exc_value.with_traceback(exc_tb)\n",
      "  File \"/home/cgebbe/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py\", line 166, in _do_get\n",
      "    return self._create_connection()\n",
      "  File \"/home/cgebbe/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py\", line 393, in _create_connection\n",
      "    return _ConnectionRecord(self)\n",
      "  File \"/home/cgebbe/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py\", line 678, in __init__\n",
      "    self.__connect()\n",
      "  File \"/home/cgebbe/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py\", line 914, in __connect\n",
      "    pool.dispatch.connect.for_modify(\n",
      "  File \"/home/cgebbe/.local/lib/python3.8/site-packages/sqlalchemy/event/attr.py\", line 473, in _exec_w_sync_on_first_run\n",
      "    self(*args, **kw)\n",
      "  File \"/home/cgebbe/.local/lib/python3.8/site-packages/sqlalchemy/event/attr.py\", line 487, in __call__\n",
      "    fn(*args, **kw)\n",
      "  File \"/home/cgebbe/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py\", line 1915, in go\n",
      "    return once_fn(*arg, **kw)\n",
      "  File \"/home/cgebbe/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py\", line 733, in first_connect\n",
      "    dialect.initialize(c)\n",
      "  File \"/home/cgebbe/.local/lib/python3.8/site-packages/sqlalchemy/dialects/postgresql/psycopg2.py\", line 656, in initialize\n",
      "    super().initialize(connection)\n",
      "  File \"/home/cgebbe/.local/lib/python3.8/site-packages/sqlalchemy/dialects/postgresql/base.py\", line 3017, in initialize\n",
      "    self._set_backslash_escapes(connection)\n",
      "  File \"/home/cgebbe/.local/lib/python3.8/site-packages/sqlalchemy/dialects/postgresql/base.py\", line 4693, in _set_backslash_escapes\n",
      "    std_string = connection.exec_driver_sql(\n",
      "  File \"/home/cgebbe/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py\", line 1771, in exec_driver_sql\n",
      "    ret = self._execute_context(\n",
      "  File \"/home/cgebbe/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py\", line 1841, in _execute_context\n",
      "    return self._exec_single_context(\n",
      "  File \"/home/cgebbe/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py\", line 1982, in _exec_single_context\n",
      "    self._handle_dbapi_exception(\n",
      "  File \"/home/cgebbe/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py\", line 2339, in _handle_dbapi_exception\n",
      "    raise sqlalchemy_exception.with_traceback(exc_info[2]) from e\n",
      "  File \"/home/cgebbe/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py\", line 1963, in _exec_single_context\n",
      "    self.dialect.do_execute(\n",
      "  File \"/home/cgebbe/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py\", line 920, in do_execute\n",
      "    cursor.execute(statement, parameters)\n",
      "sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedObject) unrecognized configuration parameter \"standard_conforming_strings\"\n",
      "\n",
      "[SQL: show standard_conforming_strings]\n",
      "(Background on this error at: https://sqlalche.me/e/20/f405)\n",
      "\n",
      "Connection info needed in SQLAlchemy format, example:\n",
      "               postgresql://username:password@hostname/dbname\n",
      "               or an existing connection: dict_keys([])\n"
     ]
    }
   ],
   "source": [
    "# somehow this doesn't work? Well, not too bad after all...\n",
    "import psycopg2.extras\n",
    "\n",
    "psycopg2.extras.register_default_json(loads=lambda x: x)\n",
    "\n",
    "conn_string = \"postgresql://{}:{}@{}:{}/{}\".format(\n",
    "    DWH_DB_USER, DWH_DB_PASSWORD, DWH_ENDPOINT, DWH_PORT, DWH_DB\n",
    ")\n",
    "print(conn_string)\n",
    "%sql $conn_string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STEP 5: Clean up your resources"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b><font color='red'>DO NOT RUN THIS UNLESS YOU ARE SURE <br/> \n",
    "    We will be using these resources in the next exercises</span></b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Cluster': {'AllowVersionUpgrade': True,\n",
       "  'AutomatedSnapshotRetentionPeriod': 1,\n",
       "  'AvailabilityZone': 'us-west-2b',\n",
       "  'ClusterCreateTime': datetime.datetime(2019, 2, 16, 6, 21, 30, 630000, tzinfo=tzutc()),\n",
       "  'ClusterIdentifier': 'dwhcluster',\n",
       "  'ClusterParameterGroups': [{'ParameterApplyStatus': 'in-sync',\n",
       "    'ParameterGroupName': 'default.redshift-1.0'}],\n",
       "  'ClusterSecurityGroups': [],\n",
       "  'ClusterStatus': 'deleting',\n",
       "  'ClusterSubnetGroupName': 'default',\n",
       "  'ClusterVersion': '1.0',\n",
       "  'DBName': 'dwh',\n",
       "  'Encrypted': False,\n",
       "  'Endpoint': {'Address': 'dwhcluster.csmamz5zxmle.us-west-2.redshift.amazonaws.com',\n",
       "   'Port': 5439},\n",
       "  'EnhancedVpcRouting': False,\n",
       "  'IamRoles': [{'ApplyStatus': 'in-sync',\n",
       "    'IamRoleArn': 'arn:aws:iam::988332130976:role/dwhRole'}],\n",
       "  'MasterUsername': 'dwhuser',\n",
       "  'NodeType': 'dc2.large',\n",
       "  'NumberOfNodes': 4,\n",
       "  'PendingModifiedValues': {},\n",
       "  'PreferredMaintenanceWindow': 'fri:10:30-fri:11:00',\n",
       "  'PubliclyAccessible': True,\n",
       "  'Tags': [],\n",
       "  'VpcId': 'vpc-54d40a2c',\n",
       "  'VpcSecurityGroups': []},\n",
       " 'ResponseMetadata': {'HTTPHeaders': {'content-length': '2041',\n",
       "   'content-type': 'text/xml',\n",
       "   'date': 'Sat, 16 Feb 2019 07:13:32 GMT',\n",
       "   'x-amzn-requestid': '5e58b2d8-31ba-11e9-b19b-0945d449b0a9'},\n",
       "  'HTTPStatusCode': 200,\n",
       "  'RequestId': '5e58b2d8-31ba-11e9-b19b-0945d449b0a9',\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### CAREFUL!!\n",
    "#-- Uncomment & run to delete the created resources\n",
    "redshift.delete_cluster( ClusterIdentifier=DWH_CLUSTER_IDENTIFIER,  SkipFinalClusterSnapshot=True)\n",
    "#### CAREFUL!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- run this block several times until the cluster really deleted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Key</th>\n",
       "      <th>Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ClusterIdentifier</td>\n",
       "      <td>dwhcluster</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NodeType</td>\n",
       "      <td>dc2.large</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ClusterStatus</td>\n",
       "      <td>deleting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MasterUsername</td>\n",
       "      <td>dwhuser</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DBName</td>\n",
       "      <td>dwh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Endpoint</td>\n",
       "      <td>{'Address': 'dwhcluster.csmamz5zxmle.us-west-2.redshift.amazonaws.com', 'Port': 5439}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>VpcId</td>\n",
       "      <td>vpc-54d40a2c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NumberOfNodes</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Key  \\\n",
       "0  ClusterIdentifier   \n",
       "1  NodeType            \n",
       "2  ClusterStatus       \n",
       "3  MasterUsername      \n",
       "4  DBName              \n",
       "5  Endpoint            \n",
       "6  VpcId               \n",
       "7  NumberOfNodes       \n",
       "\n",
       "                                                                                   Value  \n",
       "0  dwhcluster                                                                             \n",
       "1  dc2.large                                                                              \n",
       "2  deleting                                                                               \n",
       "3  dwhuser                                                                                \n",
       "4  dwh                                                                                    \n",
       "5  {'Address': 'dwhcluster.csmamz5zxmle.us-west-2.redshift.amazonaws.com', 'Port': 5439}  \n",
       "6  vpc-54d40a2c                                                                           \n",
       "7  4                                                                                      "
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myClusterProps = redshift.describe_clusters(ClusterIdentifier=DWH_CLUSTER_IDENTIFIER)['Clusters'][0]\n",
    "prettyRedshiftProps(myClusterProps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ResponseMetadata': {'HTTPHeaders': {'content-length': '200',\n",
       "   'content-type': 'text/xml',\n",
       "   'date': 'Sat, 16 Feb 2019 07:13:50 GMT',\n",
       "   'x-amzn-requestid': '694f8d91-31ba-11e9-9438-d3ce9c613ef8'},\n",
       "  'HTTPStatusCode': 200,\n",
       "  'RequestId': '694f8d91-31ba-11e9-9438-d3ce9c613ef8',\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### CAREFUL!!\n",
    "#-- Uncomment & run to delete the created resources\n",
    "iam.detach_role_policy(RoleName=DWH_IAM_ROLE_NAME, PolicyArn=\"arn:aws:iam::aws:policy/AmazonS3ReadOnlyAccess\")\n",
    "iam.delete_role(RoleName=DWH_IAM_ROLE_NAME)\n",
    "#### CAREFUL!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "toc-autonumbering": false,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
